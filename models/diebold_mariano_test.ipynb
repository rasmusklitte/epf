{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found. Using CPU.\n",
      "TensorFlow Version: 2.18.0\n",
      "Available GPUs: []\n"
     ]
    }
   ],
   "source": [
    "#!pip install tensorflow==2.15.0  # Erstat med den ønskede version. Denne er nødvendig for at bruge TCN\n",
    "#!pip install keras_tuner\n",
    "#!pip install keras-tcn\n",
    "# Grundlæggende pakker\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep Learning med TensorFlow og Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "\n",
    "# Check if GPU is available and configure memory growth\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if physical_devices:\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU is available and memory growth enabled\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Memory growth setting failed:\", e)\n",
    "else:\n",
    "    print(\"No GPU found. Using CPU.\")\n",
    "\n",
    "# Check TensorFlow version for reference\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "\n",
    "# Additional GPU details\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"Available GPUs:\", gpus)\n",
    "\n",
    "# Optional: To specify a particular GPU, if multiple are available\n",
    "gpu_number = 0  # Change this index if needed\n",
    "if len(gpus) >= 2:\n",
    "    try:\n",
    "        tf.config.experimental.set_visible_devices(gpus[gpu_number], 'GPU')\n",
    "        print(f\"Using GPU: {gpus[gpu_number]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Failed to set specific GPU:\", e)\n",
    "\n",
    "ROOT_PATH = '/Users/rasmusklitteandersen/Library/CloudStorage/GoogleDrive-rasmusklitteandersen@gmail.com/Mit drev/speciale/'\n",
    "\n",
    "# ROOT_PATH = '/content/drive/MyDrive/speciale/'\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# gpu_info = !nvidia-smi\n",
    "# gpu_info = '\\n'.join(gpu_info)\n",
    "# if gpu_info.find('failed') >= 0:\n",
    "#   print('Not connected to a GPU')\n",
    "# else:\n",
    "#   print(gpu_info)\n",
    "\n",
    "# from psutil import virtual_memory\n",
    "# ram_gb = virtual_memory().total / 1e9\n",
    "# print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "\n",
    "# if ram_gb < 20:\n",
    "#   print('Not using a high-RAM runtime')\n",
    "# else:\n",
    "#   print('You are using a high-RAM runtime!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting training with configuration:\n",
      "INFO:root:Data path: /Users/rasmusklitteandersen/Library/CloudStorage/GoogleDrive-rasmusklitteandersen@gmail.com/Mit drev/speciale/data/final_dataset_test.csv\n",
      "INFO:root:Model path: /Users/rasmusklitteandersen/Library/CloudStorage/GoogleDrive-rasmusklitteandersen@gmail.com/Mit drev/speciale/models/\n",
      "INFO:root:Model path: /Users/rasmusklitteandersen/Library/CloudStorage/GoogleDrive-rasmusklitteandersen@gmail.com/Mit drev/speciale/models//tuning/\n",
      "INFO:root:Model path: /Users/rasmusklitteandersen/Library/CloudStorage/GoogleDrive-rasmusklitteandersen@gmail.com/Mit drev/speciale/results/\n",
      "INFO:root:Include Lags: True, Include Season Vars: False, Include Weather: False\n",
      "INFO:root:Training epochs: 30, Final model epochs: 50, Batch size: 64\n"
     ]
    }
   ],
   "source": [
    "# Set up paths and configurations\n",
    "#ROOT_PATH = '/content/drive/MyDrive/speciale/'\n",
    "sys.path.append(ROOT_PATH)\n",
    "os.chdir(ROOT_PATH)\n",
    "\n",
    "# Import custom utilities and modules\n",
    "from utils.misc import LoadData, TerminateNaN, Plotting, EvaluationMetric\n",
    "from utils.models import ModelTrainer\n",
    "\n",
    "# ===== CONFIGURATION SECTION =====\n",
    "# Paths\n",
    "DATA_PATH = f'{ROOT_PATH}data/final_dataset_test.csv'\n",
    "MODEL_PATH = f'{ROOT_PATH}models/'\n",
    "IMAGE_PATH = f'{ROOT_PATH}/images/'\n",
    "LOG_DIR = f'{MODEL_PATH}/logs/'\n",
    "TUNING_DIR = f'{MODEL_PATH}/tuning/'\n",
    "RESULTS_DIR = f'{ROOT_PATH}results/'\n",
    "TABLES_DIR = f'{ROOT_PATH}tables/'\n",
    "\n",
    "# Flags and Options\n",
    "INCLUDE_LAGS = True\n",
    "INCLUDE_SEASON_VARS = False\n",
    "INCLUDE_WEATHER = False\n",
    "TEST = False\n",
    "TIME_START = '2019-10-31'\n",
    "TIME_END_PERIODS = ['2021-09-30', '2023-01-01', '2024-07-01']\n",
    "MODELS = ['LSTM', 'TCN', 'Hybrid', 'Transformer']\n",
    "#MODELS = ['Hybrid', 'Transformer']\n",
    "TUNER = 'Hyperband'\n",
    "\n",
    "# Training Parameters\n",
    "TRAINING_EPOCH = 30\n",
    "FINAL_MODEL_EPOCH = 50\n",
    "BATCH_SIZE = 64\n",
    "LOSS = 'mean_absolute_error'\n",
    "\n",
    "# Generate dynamic strings based on flags\n",
    "def get_extra_info():\n",
    "    extra_info = ''\n",
    "    if not INCLUDE_WEATHER:\n",
    "        extra_info += '_no_weather'\n",
    "    if not INCLUDE_LAGS:\n",
    "        extra_info += '_no_lags'\n",
    "    if not INCLUDE_SEASON_VARS:\n",
    "        extra_info += '_no_season_vars'\n",
    "    return extra_info\n",
    "\n",
    "# ===== LOGGING SETUP =====\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# ===== FUNCTIONS =====\n",
    "\n",
    "def reload_utils_misc():\n",
    "    \"\"\"Function to reload utils.misc module if changes are made.\"\"\"\n",
    "    import utils.misc\n",
    "    importlib.reload(utils.misc)\n",
    "\n",
    "\n",
    "def setup_directories(test_mode, image_path, log_dir, tuning_dir, results_dir, tables_dir):\n",
    "    \"\"\"Set up directories based on whether TEST mode is enabled.\"\"\"\n",
    "    test_suffix = 'test/'\n",
    "    \n",
    "    if test_mode: \n",
    "        image_path = f\"{image_path}{test_suffix}\"\n",
    "        log_dir = f\"{log_dir}{test_suffix}\"\n",
    "        tuning_dir = f\"{tuning_dir}{test_suffix}\"\n",
    "        results_dir = f\"{results_dir}{test_suffix}\"\n",
    "        tables_dir = f\"{tables_dir}{test_suffix}\"\n",
    "        \n",
    "    return image_path, log_dir, tuning_dir, results_dir, tables_dir\n",
    "\n",
    "\n",
    "def initialize_data_loader():\n",
    "    \"\"\"Initialize the data loading utility with required flags.\"\"\"\n",
    "    return LoadData(INCLUDE_LAGS, INCLUDE_SEASON_VARS, INCLUDE_WEATHER, TUNER)\n",
    "\n",
    "def initialize_evaluation_metric():\n",
    "    \"\"\"Initialize the evaluation metric utility with required flags.\"\"\"\n",
    "    return EvaluationMetric(INCLUDE_LAGS, INCLUDE_SEASON_VARS, INCLUDE_WEATHER, TUNER)\n",
    "\n",
    "# ===== MAIN SCRIPT =====\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Setup directories based on TEST mode\n",
    "    # dirs = setup_directories(TEST)\n",
    "    IMAGE_PATH, LOG_DIR, TUNING_DIR, RESULTS_DIR, TABLES_DIR = setup_directories(\n",
    "    test_mode=TEST, \n",
    "    image_path=IMAGE_PATH, \n",
    "    log_dir=LOG_DIR, \n",
    "    tuning_dir=TUNING_DIR, \n",
    "    results_dir=RESULTS_DIR, \n",
    "    tables_dir=TABLES_DIR\n",
    "    )\n",
    "\n",
    "    extra_info = get_extra_info()\n",
    "    \n",
    "    # Reload utils if changes were made\n",
    "    reload_utils_misc()\n",
    "\n",
    "    # Initialize components\n",
    "    load_data = initialize_data_loader()\n",
    "    terminate_nan = TerminateNaN()\n",
    "    evaluation_metric = initialize_evaluation_metric()\n",
    "\n",
    "    # Set random seeds for reproducibility\n",
    "    tf.random.set_seed(14)\n",
    "    np.random.seed(14)\n",
    "\n",
    "    # Log basic configuration\n",
    "    logger.info(f\"Starting training with configuration:\")\n",
    "    logger.info(f\"Data path: {DATA_PATH}\")\n",
    "    logger.info(f\"Model path: {MODEL_PATH}\")\n",
    "    logger.info(f\"Model path: {TUNING_DIR}\")\n",
    "    logger.info(f\"Model path: {RESULTS_DIR}\")\n",
    "    logger.info(f\"Include Lags: {INCLUDE_LAGS}, Include Season Vars: {INCLUDE_SEASON_VARS}, Include Weather: {INCLUDE_WEATHER}\")\n",
    "    logger.info(f\"Training epochs: {TRAINING_EPOCH}, Final model epochs: {FINAL_MODEL_EPOCH}, Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time end: 2024-07-01\n",
      "Time period: 2019-10-31_to_2024-07-01\n",
      "LSTM\n",
      "Diebold-Mariano Test Statistic: -0.9471812583297132\n",
      "P-Value: 0.3435464237755075\n",
      "The difference in forecasting errors is not statistically significant.\n",
      "[{'Time Period': '2019-10-31_to_2024-07-01', 'Best Model': 'TCN', 'Compared Model': 'LSTM', 'Diebold-Mariano Statistic': -0.9471812583297132, 'P-Value': 0.3435464237755075, 'Interpretation': 'No statistically significant difference'}]\n",
      "TCN\n",
      "Diebold-Mariano Test Statistic: nan\n",
      "P-Value: nan\n",
      "The difference in forecasting errors is not statistically significant.\n",
      "[{'Time Period': '2019-10-31_to_2024-07-01', 'Best Model': 'TCN', 'Compared Model': 'LSTM', 'Diebold-Mariano Statistic': -0.9471812583297132, 'P-Value': 0.3435464237755075, 'Interpretation': 'No statistically significant difference'}, {'Time Period': '2019-10-31_to_2024-07-01', 'Best Model': 'TCN', 'Compared Model': 'TCN', 'Diebold-Mariano Statistic': nan, 'P-Value': nan, 'Interpretation': 'No statistically significant difference'}]\n",
      "Hybrid\n",
      "Diebold-Mariano Test Statistic: -3.56023143588197\n",
      "P-Value: 0.00037052808977011686\n",
      "The difference in forecasting errors is statistically significant.\n",
      "[{'Time Period': '2019-10-31_to_2024-07-01', 'Best Model': 'TCN', 'Compared Model': 'LSTM', 'Diebold-Mariano Statistic': -0.9471812583297132, 'P-Value': 0.3435464237755075, 'Interpretation': 'No statistically significant difference'}, {'Time Period': '2019-10-31_to_2024-07-01', 'Best Model': 'TCN', 'Compared Model': 'TCN', 'Diebold-Mariano Statistic': nan, 'P-Value': nan, 'Interpretation': 'No statistically significant difference'}, {'Time Period': '2019-10-31_to_2024-07-01', 'Best Model': 'TCN', 'Compared Model': 'Hybrid', 'Diebold-Mariano Statistic': -3.56023143588197, 'P-Value': 0.00037052808977011686, 'Interpretation': 'Statistically significant difference'}]\n",
      "Transformer\n",
      "Diebold-Mariano Test Statistic: -2.221239219565397\n",
      "P-Value: 0.026334763124417293\n",
      "The difference in forecasting errors is statistically significant.\n",
      "[{'Time Period': '2019-10-31_to_2024-07-01', 'Best Model': 'TCN', 'Compared Model': 'LSTM', 'Diebold-Mariano Statistic': -0.9471812583297132, 'P-Value': 0.3435464237755075, 'Interpretation': 'No statistically significant difference'}, {'Time Period': '2019-10-31_to_2024-07-01', 'Best Model': 'TCN', 'Compared Model': 'TCN', 'Diebold-Mariano Statistic': nan, 'P-Value': nan, 'Interpretation': 'No statistically significant difference'}, {'Time Period': '2019-10-31_to_2024-07-01', 'Best Model': 'TCN', 'Compared Model': 'Hybrid', 'Diebold-Mariano Statistic': -3.56023143588197, 'P-Value': 0.00037052808977011686, 'Interpretation': 'Statistically significant difference'}, {'Time Period': '2019-10-31_to_2024-07-01', 'Best Model': 'TCN', 'Compared Model': 'Transformer', 'Diebold-Mariano Statistic': -2.221239219565397, 'P-Value': 0.026334763124417293, 'Interpretation': 'Statistically significant difference'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/speciale-env/lib/python3.12/site-packages/statsmodels/tsa/stattools.py:702: RuntimeWarning: invalid value encountered in divide\n",
      "  acf = avf[: nlags + 1] / avf[0]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import acf\n",
    "from scipy import stats\n",
    "\n",
    "# Sample function for Diebold-Mariano test\n",
    "def diebold_mariano_test(errors_model1, errors_model2):\n",
    "    d = errors_model1 - errors_model2\n",
    "    d = np.ravel(d)\n",
    "    mean_d = np.mean(d)\n",
    "    acf_values = acf(d, fft=True)\n",
    "    variance_d = np.var(d) * (1 + 2 * sum(acf_values[1:])) / len(d)\n",
    "    dm_stat = mean_d / np.sqrt(variance_d)\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "    return dm_stat, p_value\n",
    "\n",
    "######### DISSE VÆRDIER SKAL MODIFICERES ######### \n",
    "TIME_END = TIME_END_PERIODS[2]\n",
    "BEST_MODEL = 'TCN'\n",
    "print(f'Time end: {TIME_END}')\n",
    "endswith = ['__Hyperband', '_ex_wheater', '__Hyperband_ex_season_dummies_ex_wheater']\n",
    "endswith_path = endswith[1]\n",
    "###################################################\n",
    "\n",
    "\n",
    "df, TIME_PERIOD = load_data.load_and_preprocess_data(DATA_PATH, TIME_START, TIME_END)\n",
    "print(f'Time period: {TIME_PERIOD}')\n",
    "\n",
    "results = []\n",
    "with open(f'{RESULTS_DIR}predictions/{BEST_MODEL}/{BEST_MODEL}_{TIME_PERIOD}_Hyperband_predictions{endswith_path}.pkl', 'rb') as f:\n",
    "        predictions_1 = pickle.load(f)\n",
    "\n",
    "for i in range(len(MODELS)):  \n",
    "    \n",
    "    MODEL = MODELS[i]\n",
    "    print(MODEL)\n",
    "    with open(f'{RESULTS_DIR}predictions/{MODEL}/{MODEL}_{TIME_PERIOD}_Hyperband_predictions{endswith_path}.pkl', 'rb') as f:\n",
    "        predictions_2 = pickle.load(f)\n",
    "\n",
    "    log_dir, tuning_dir = load_data.setup_directories(LOG_DIR, TUNING_DIR, TIME_PERIOD, MODEL)\n",
    "    datasets, y, X_train, X_test, scaler_y, y_test = load_data.split_and_scale_data(df)\n",
    "\n",
    "    errors_model1 = np.abs(np.array(y_test[:len(predictions_1)]) - predictions_1)\n",
    "    errors_model2 = np.abs(np.array(y_test[:len(predictions_1)]) - predictions_2)\n",
    "    d = errors_model1 - errors_model2\n",
    "\n",
    "    # Perform Diebold-Mariano test on the errors\n",
    "    dm_stat, p_value = diebold_mariano_test(errors_model1, errors_model2)\n",
    "    print(f\"Diebold-Mariano Test Statistic: {dm_stat}\")\n",
    "    print(f\"P-Value: {p_value}\")\n",
    "\n",
    "    # Interpretation\n",
    "    if p_value < 0.1:\n",
    "        print(\"The difference in forecasting errors is statistically significant.\")\n",
    "    else:\n",
    "        print(\"The difference in forecasting errors is not statistically significant.\")\n",
    "    # Collect results in a list for the CSV\n",
    "    \n",
    "\n",
    "    interpretation = (\n",
    "            \"Statistically significant difference\" if p_value < 0.1\n",
    "            else \"No statistically significant difference\"\n",
    "        )\n",
    "\n",
    "    # Save results\n",
    "    results.append({\n",
    "        \"Time Period\": TIME_PERIOD,\n",
    "        \"Best Model\": BEST_MODEL,\n",
    "        \"Compared Model\": MODEL,\n",
    "        \"Diebold-Mariano Statistic\": dm_stat,\n",
    "        \"P-Value\": p_value,\n",
    "        \"Interpretation\": interpretation\n",
    "    })\n",
    "    print(results)\n",
    "\n",
    "# Convert results to a DataFrame and save to CSV\n",
    "results_df = pd.DataFrame(results)\n",
    "csv_path = f\"{RESULTS_DIR}diebold_mariano/diebold_mariano_results_{TIME_PERIOD}{extra_info}.csv\"\n",
    "results_df.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#mae = metrics.mae(np.array(y_test[:len(predictions)]), np.array(predictions))\n",
    "\n",
    "errors_model1 = np.abs(np.array(y_test[:len(predictions_1)]) - predictions_1)\n",
    "errors_model2 = np.abs(np.array(y_test[:len(predictions_1)]) - predictions_2)\n",
    "d = errors_model1 - errors_model2\n",
    "print(d)\n",
    "\n",
    "# Sample function for Diebold-Mariano test\n",
    "def diebold_mariano_test(errors_model1, errors_model2):\n",
    "    d = errors_model1 - errors_model2\n",
    "    d = np.ravel(d)\n",
    "    mean_d = np.mean(d)\n",
    "    acf_values = acf(d, fft=True)\n",
    "    variance_d = np.var(d) * (1 + 2 * sum(acf_values[1:])) / len(d)\n",
    "    dm_stat = mean_d / np.sqrt(variance_d)\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n",
    "    return dm_stat, p_value\n",
    "\n",
    "# Perform Diebold-Mariano test on the errors\n",
    "dm_stat, p_value = diebold_mariano_test(errors_model1, errors_model2)\n",
    "print(f\"Diebold-Mariano Test Statistic: {dm_stat}\")\n",
    "print(f\"P-Value: {p_value}\")\n",
    "\n",
    "# Interpretation\n",
    "if p_value < 0.05:\n",
    "    print(\"The difference in forecasting errors is statistically significant.\")\n",
    "else:\n",
    "    print(\"The difference in forecasting errors is not statistically significant.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "speciale-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
