{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grundlæggende pakker\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import logging\n",
    "import importlib\n",
    "\n",
    "ROOT_PATH = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths and configurations\n",
    "#ROOT_PATH = '/content/drive/MyDrive/speciale/'\n",
    "sys.path.append(ROOT_PATH)\n",
    "os.chdir(ROOT_PATH)\n",
    "\n",
    "# Import custom utilities and modules\n",
    "from utils.misc import LoadData, EvaluationMetric\n",
    "from utils import metrics \n",
    "\n",
    "# ===== CONFIGURATION SECTION =====\n",
    "# Paths\n",
    "DATA_PATH = f'{ROOT_PATH}data/final_dataset_test.csv'\n",
    "MODEL_PATH = f'{ROOT_PATH}models/'\n",
    "IMAGE_PATH = f'{ROOT_PATH}/images/'\n",
    "LOG_DIR = f'{MODEL_PATH}/logs/'\n",
    "TUNING_DIR = f'{MODEL_PATH}/tuning/'\n",
    "RESULTS_DIR = f'{ROOT_PATH}results/'\n",
    "TABLES_DIR = f'{ROOT_PATH}tables/'\n",
    "\n",
    "# Flags and Options\n",
    "INCLUDE_LAGS = True\n",
    "INCLUDE_SEASON_VARS = True\n",
    "INCLUDE_WEATHER = True\n",
    "TEST = False\n",
    "TIME_START = '2019-10-31'\n",
    "TIME_END = '2021-09-30'\n",
    "TIME_END_PERIODS = ['2021-09-30', '2023-01-01', '2024-07-01']\n",
    "MODELS = ['LSTM', 'TCN', 'Hybrid', 'Transformer']\n",
    "TUNER = ''\n",
    "\n",
    "# Generate dynamic strings based on flags\n",
    "def get_extra_info():\n",
    "    extra_info = ''\n",
    "    if not INCLUDE_WEATHER:\n",
    "        extra_info += '_no_weather'\n",
    "    if not INCLUDE_LAGS:\n",
    "        extra_info += '_no_lags'\n",
    "    if not INCLUDE_SEASON_VARS:\n",
    "        extra_info += '_no_season_vars'\n",
    "    return extra_info\n",
    "\n",
    "# ===== LOGGING SETUP =====\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger()\n",
    "\n",
    "# ===== FUNCTIONS =====\n",
    "def reload_utils_misc():\n",
    "    \"\"\"Function to reload utils.misc module if changes are made.\"\"\"\n",
    "    import utils.misc\n",
    "    importlib.reload(utils.misc)\n",
    "\n",
    "def setup_directories(test_mode):\n",
    "    \"\"\"Set up directories based on whether TEST mode is enabled.\"\"\"\n",
    "    test_suffix = 'test/' if test_mode else ''\n",
    "    return {\n",
    "        'image_path': f\"{IMAGE_PATH}{test_suffix}\",\n",
    "        'log_dir': f\"{LOG_DIR}{test_suffix}\",\n",
    "        'tuning_dir': f\"{TUNING_DIR}{test_suffix}\",\n",
    "        'results_dir': f\"{RESULTS_DIR}{test_suffix}\",\n",
    "        'tables_dir': f\"{TABLES_DIR}{test_suffix}\"\n",
    "    }\n",
    "\n",
    "def initialize_data_loader():\n",
    "    \"\"\"Initialize the data loading utility with required flags.\"\"\"\n",
    "    return LoadData(INCLUDE_LAGS, INCLUDE_SEASON_VARS, INCLUDE_WEATHER, TUNER)\n",
    "\n",
    "def initialize_evaluation_metric():\n",
    "    \"\"\"Initialize the evaluation metric utility with required flags.\"\"\"\n",
    "    return EvaluationMetric(INCLUDE_LAGS, INCLUDE_SEASON_VARS, INCLUDE_WEATHER, TUNER)\n",
    "\n",
    "# ===== MAIN SCRIPT =====\n",
    "if __name__ == \"__main__\":\n",
    "    # Setup directories based on TEST mode\n",
    "    dirs = setup_directories(TEST)\n",
    "    extra_info = get_extra_info()\n",
    "    \n",
    "    # Reload utils if changes were made\n",
    "    reload_utils_misc()\n",
    "\n",
    "    # Initialize components\n",
    "    load_data = initialize_data_loader()\n",
    "    evaluation_metric = initialize_evaluation_metric()\n",
    "\n",
    "    # Set random seeds for reproducibility\n",
    "    #tf.random.set_seed(14)\n",
    "    np.random.seed(14)\n",
    "\n",
    "    # Log basic configuration\n",
    "    logger.info(f\"Starting training with configuration:\")\n",
    "    logger.info(f\"Data path: {DATA_PATH}\")\n",
    "    logger.info(f\"Model path: {MODEL_PATH}\")\n",
    "    logger.info(f\"Include Lags: {INCLUDE_LAGS}, Include Season Vars: {INCLUDE_SEASON_VARS}, Include Weather: {INCLUDE_WEATHER}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = 'Naive'\n",
    "load_data = LoadData(INCLUDE_LAGS, INCLUDE_SEASON_VARS, INCLUDE_WEATHER)\n",
    "df, TIME_PERIOD = load_data.load_and_preprocess_data(DATA_PATH, TIME_START, TIME_END)\n",
    "log_dir, tuning_dir = load_data.setup_directories(LOG_DIR, TUNING_DIR, TIME_PERIOD, MODEL)\n",
    "datasets, y, X_train, X_test, scaler_y, y_test = load_data.split_and_scale_data(df)\n",
    "\n",
    "prices = df.iloc[len(df) - len(datasets['y_test']):, [df.columns.get_loc('Day Ahead Spot Price')]]\n",
    "prices  = pd.DataFrame(prices)\n",
    "\n",
    "# Opret en ny kolonne til prediction\n",
    "prices['forecast'] = None\n",
    "\n",
    "# Beregn forecast for hver time ved at tage gennemsnittet af den foregående uges tilsvarende tidspunkter\n",
    "def rolling_forecast(df, window_size=24*7):  # window_size for en hel uge\n",
    "    for current_time in df.index[window_size:]:  # Start fra den første komplette uge fremad\n",
    "        # Slut her er aktuelt tidspunkt minus en uge\n",
    "        window_start = current_time - pd.Timedelta(days=7)\n",
    "        \n",
    "        # Slice med de seneste syv dage frem til current_time (ikke inklusive)\n",
    "        relevant_data = df.loc[window_start:current_time, 'Day Ahead Spot Price']\n",
    "        \n",
    "        # Beregn gennemsnit for disse data\n",
    "        df.at[current_time, 'forecast'] = relevant_data.mean()\n",
    "\n",
    "# Anvend funktionen til at beregne forecast\n",
    "rolling_forecast(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metrics = metrics.evaluate_all(np.array(datasets['y_test']), prices['forecast'])\n",
    "logger.info('Test scores:')\n",
    "logger.info(test_metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR-X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INCLUDE_LAGS = True\n",
    "INCLUDE_SEASON_VARS = True\n",
    "INCLUDE_WEATHER = True\n",
    "MODEL = 'AR-X'\n",
    "TIME_END = '2024-07-01'\n",
    "\n",
    "\n",
    "load_data = LoadData(INCLUDE_LAGS, INCLUDE_SEASON_VARS, INCLUDE_WEATHER)\n",
    "df, TIME_PERIOD = load_data.load_and_preprocess_data(DATA_PATH, TIME_START, TIME_END)\n",
    "log_dir, tuning_dir = load_data.setup_directories(LOG_DIR, TUNING_DIR, TIME_PERIOD, MODEL)\n",
    "datasets, y, X_train, X_test, scaler_y, y_test = load_data.split_and_scale_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and separate 'Day Ahead Spot Price' as the endogenous variable\n",
    "data = df['Day Ahead Spot Price'].values.reshape(-1, 1)  # Endogenous variable\n",
    "exog = df.drop(columns=['Day Ahead Spot Price']).values  # All other variables as exogenous\n",
    "\n",
    "# Handle any NaN values\n",
    "data = np.nan_to_num(data)\n",
    "exog = np.nan_to_num(exog)\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_data, test_data = data[:train_size].flatten(), data[train_size:].flatten()\n",
    "train_exog, test_exog = exog[:train_size], exog[train_size:]\n",
    "\n",
    "# Define parameters\n",
    "sequence_length = 24 * 2   # Use the last 7 days (168 hours) to predict the next 24 hours\n",
    "prediction_length = 24     # Forecast the next 24 hours\n",
    "\n",
    "# Iterative forecasting for the entire test set using AR-X\n",
    "predictions = []\n",
    "history_data = list(train_data)  # History for endogenous data\n",
    "history_exog = list(train_exog)  # History for exogenous variables\n",
    "\n",
    "# Convert history_exog to numpy array and select the last `sequence_length` rows\n",
    "history_exog_array = np.array(history_exog)\n",
    "\n",
    "mod = AutoReg(endog=history_data, lags=2, exog=history_exog)\n",
    "res = mod.fit()\n",
    "pred = res.predict(exog_oos=test_exog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load data and separate 'Day Ahead Spot Price' as the endogenous variable\n",
    "data = df['Day Ahead Spot Price'].values.reshape(-1, 1)  # Endogenous variable\n",
    "exog = df.drop(columns=['Day Ahead Spot Price']).values  # All other variables as exogenous\n",
    "\n",
    "# Handle any NaN values\n",
    "data = np.nan_to_num(data)\n",
    "exog = np.nan_to_num(exog)\n",
    "\n",
    "# Split data into training and test sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_data, test_data = data[:train_size].flatten(), data[train_size:].flatten()\n",
    "train_exog, test_exog = exog[:train_size], exog[train_size:]\n",
    "\n",
    "# Define parameters\n",
    "sequence_length = 24 * 2   # Use the last 7 days (168 hours) to predict the next 24 hours\n",
    "prediction_length = 24     # Forecast the next 24 hours\n",
    "\n",
    "# Iterative forecasting for the entire test set using AR-X\n",
    "predictions = []\n",
    "history_data = list(train_data)  # History for endogenous data\n",
    "history_exog = list(train_exog)  # History for exogenous variables\n",
    "\n",
    "# Convert history_exog to numpy array and select the last `sequence_length` rows\n",
    "history_exog_array = np.array(history_exog)\n",
    "\n",
    "mod = AutoReg(endog=history_data, lags=2, exog=history_exog)\n",
    "res = mod.fit()\n",
    "pred = res.predict(exog_oos=test_exog)\n",
    "\n",
    "# Train AR-X model on the most recent sequence_length data points\n",
    "model = AutoReg(endog=history_data, lags=2, exog=history_exog_array)\n",
    "model_fit = model.fit()\n",
    "# Get all model parameters\n",
    "print(model_fit.summary())\n",
    "\n",
    "for i in range(0, len(test_data) - sequence_length, prediction_length):\n",
    "   \n",
    "    # Forecast the next 24 hours using the corresponding exogenous variables\n",
    "    # Setting start=0 and end=prediction_length-1 to only forecast 24 steps\n",
    "    forecast = model_fit.predict(\n",
    "        start=0,\n",
    "        end=prediction_length - 1,\n",
    "        exog_oos=test_exog[i:i + prediction_length]\n",
    "    )\n",
    "    predictions.extend(forecast)\n",
    "\n",
    "    # Update the history with the latest actual values and exogenous variables\n",
    "    history_data.extend(test_data[i:i + prediction_length])\n",
    "    history_exog.extend(test_exog[i:i + prediction_length])\n",
    "\n",
    "# Inverse transform the predictions and actual values to original scale\n",
    "predictions = np.array(predictions).reshape(-1, 1).flatten()\n",
    "actual_values = test_data[:len(predictions)].reshape(-1, 1).flatten()\n",
    "\n",
    "test_metrics = metrics.evaluate_all(actual_values, np.nan_to_num(predictions))\n",
    "logger.info('Test scores:')\n",
    "logger.info(test_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importér nødvendige biblioteker\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "MODEL = 'AR'\n",
    "df, TIME_PERIOD = load_data.load_and_preprocess_data(DATA_PATH, TIME_START, TIME_END)\n",
    "data = df['Day Ahead Spot Price'].values.reshape(-1, 1)\n",
    "\n",
    "# Tjek og håndter eventuelle NaN-værdier\n",
    "data = np.nan_to_num(data)\n",
    "\n",
    "# Split data i trænings- og testdata\n",
    "train_size = int(len(data) * 0.8)\n",
    "train_data, test_data = data[:train_size].flatten(), data[train_size:].flatten()\n",
    "\n",
    "# Definér parametre\n",
    "sequence_length = 24 * 7   # Brug de seneste 7 dage (168 timer) til at forudsige de næste 24 timer\n",
    "prediction_length = 24     # Forudsige de næste 24 timer\n",
    "\n",
    "# Iterativ forudsigelse for hele test-sættet med ARIMA\n",
    "predictions = []\n",
    "history = list(train_data)  # Brug træningsdata som historik til ARIMA-modellen\n",
    "\n",
    "# Træn ARIMA-modellen på den aktuelle historik\n",
    "model = ARIMA(history, order=(2,0,0))  \n",
    "model_fit = model.fit()\n",
    "\n",
    "for i in range(0, len(test_data) - sequence_length, prediction_length):\n",
    "    \n",
    "    # Forudsig de næste 24 timer\n",
    "    forecast = model_fit.forecast(steps=prediction_length)\n",
    "    predictions.extend(forecast)\n",
    "\n",
    "    # Opdater historikken med de nyeste forudsigelser\n",
    "    history.extend(test_data[i:i + prediction_length])\n",
    "\n",
    "# Inverse transform the predictions and actual values to original scale\n",
    "predictions = np.array(predictions).reshape(-1, 1).flatten()\n",
    "actual_values = test_data[:len(predictions)].reshape(-1, 1).flatten()\n",
    "\n",
    "test_metrics = metrics.evaluate_all(actual_values, np.nan_to_num(predictions))\n",
    "logger.info('Test scores:')\n",
    "logger.info(test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "applied_corp-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
