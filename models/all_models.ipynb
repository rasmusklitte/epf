{"cells":[{"cell_type":"code","execution_count":null,"id":"031d798d-c6f1-4210-ac31-50a645cdb08c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3641,"status":"ok","timestamp":1726143299448,"user":{"displayName":"Rasmus Klitte Andersen","userId":"00812341989558572059"},"user_tz":-120},"id":"031d798d-c6f1-4210-ac31-50a645cdb08c","outputId":"d651387e-35de-4e34-f412-7babe22b2f55","tags":[]},"outputs":[],"source":["#!pip install tensorflow==2.15.0  # Erstat med den ønskede version. Denne er nødvendig for at bruge TCN\n","#!pip install keras_tuner\n","#!pip install keras-tcn\n","# Grundlæggende pakker\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Deep Learning med TensorFlow og Keras\n","import tensorflow as tf\n","from tensorflow.keras.utils import plot_model\n","\n","import logging\n","import os\n","import sys\n","import importlib\n","\n","# Check if GPU is available and configure memory growth\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if physical_devices:\n","    try:\n","        for gpu in physical_devices:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        print(\"GPU is available and memory growth enabled\")\n","    except RuntimeError as e:\n","        print(\"Memory growth setting failed:\", e)\n","else:\n","    print(\"No GPU found. Using CPU.\")\n","\n","# Check TensorFlow version for reference\n","print(\"TensorFlow Version:\", tf.__version__)\n","\n","# Additional GPU details\n","gpus = tf.config.list_physical_devices('GPU')\n","print(\"Available GPUs:\", gpus)\n","\n","# Optional: To specify a particular GPU, if multiple are available\n","gpu_number = 0  # Change this index if needed\n","if len(gpus) >= 2:\n","    try:\n","        tf.config.experimental.set_visible_devices(gpus[gpu_number], 'GPU')\n","        print(f\"Using GPU: {gpus[gpu_number]}\")\n","    except RuntimeError as e:\n","        print(\"Failed to set specific GPU:\", e)\n","\n","ROOT_PATH = ''\n","\n","# ROOT_PATH = '/content/drive/MyDrive/'\n","# from google.colab import drive\n","# drive.mount('/content/drive')\n","\n","# gpu_info = !nvidia-smi\n","# gpu_info = '\\n'.join(gpu_info)\n","# if gpu_info.find('failed') >= 0:\n","#   print('Not connected to a GPU')\n","# else:\n","#   print(gpu_info)\n","\n","# from psutil import virtual_memory\n","# ram_gb = virtual_memory().total / 1e9\n","# print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","# if ram_gb < 20:\n","#   print('Not using a high-RAM runtime')\n","# else:\n","#   print('You are using a high-RAM runtime!')"]},{"cell_type":"code","execution_count":null,"id":"3c6ce2ad","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3134,"status":"ok","timestamp":1726143319984,"user":{"displayName":"Rasmus Klitte Andersen","userId":"00812341989558572059"},"user_tz":-120},"id":"3c6ce2ad","outputId":"73a47ae1-b72a-43c6-ba9a-ad832bcfa2a7"},"outputs":[],"source":["# Set up paths and configurations\n","#ROOT_PATH = '/content/drive/MyDrive/speciale/'\n","sys.path.append(ROOT_PATH)\n","os.chdir(ROOT_PATH)\n","\n","# Import custom utilities and modules\n","from utils.misc import LoadData, TerminateNaN, Plotting, EvaluationMetric\n","from utils.models import ModelTrainer\n","\n","# ===== CONFIGURATION SECTION =====\n","# Paths\n","DATA_PATH = f'{ROOT_PATH}data/final_dataset_test.csv'\n","MODEL_PATH = f'{ROOT_PATH}models/'\n","IMAGE_PATH = f'{ROOT_PATH}/images/'\n","LOG_DIR = f'{MODEL_PATH}/logs/'\n","TUNING_DIR = f'{MODEL_PATH}/tuning/'\n","RESULTS_DIR = f'{ROOT_PATH}results/'\n","TABLES_DIR = f'{ROOT_PATH}tables/'\n","\n","# Flags and Options\n","INCLUDE_LAGS = True\n","INCLUDE_SEASON_VARS = True\n","INCLUDE_WEATHER = True\n","TEST = False\n","TIME_START = '2019-10-31'\n","TIME_END_PERIODS = ['2021-09-30', '2023-01-01', '2024-07-01']\n","MODELS = ['LSTM', 'TCN', 'Hybrid', 'Transformer']\n","TUNER = 'Hyperband'\n","\n","# Training Parameters\n","TRAINING_EPOCH = 30\n","FINAL_MODEL_EPOCH = 50\n","BATCH_SIZE = 64\n","LOSS = 'mean_absolute_error'\n","\n","# Generate dynamic strings based on flags\n","def get_extra_info():\n","    extra_info = ''\n","    if not INCLUDE_WEATHER:\n","        extra_info += '_no_weather'\n","    if not INCLUDE_LAGS:\n","        extra_info += '_no_lags'\n","    if not INCLUDE_SEASON_VARS:\n","        extra_info += '_no_season_vars'\n","    return extra_info\n","\n","# ===== LOGGING SETUP =====\n","logging.basicConfig(level=logging.INFO)\n","logger = logging.getLogger()\n","\n","# ===== FUNCTIONS =====\n","\n","def reload_utils_misc():\n","    \"\"\"Function to reload utils.misc module if changes are made.\"\"\"\n","    import utils.misc\n","    importlib.reload(utils.misc)\n","\n","\n","def setup_directories(test_mode, image_path, log_dir, tuning_dir, results_dir, tables_dir):\n","    \"\"\"Set up directories based on whether TEST mode is enabled.\"\"\"\n","    test_suffix = 'test/'\n","    \n","    if test_mode: \n","        image_path = f\"{image_path}{test_suffix}\"\n","        log_dir = f\"{log_dir}{test_suffix}\"\n","        tuning_dir = f\"{tuning_dir}{test_suffix}\"\n","        results_dir = f\"{results_dir}{test_suffix}\"\n","        tables_dir = f\"{tables_dir}{test_suffix}\"\n","        \n","    return image_path, log_dir, tuning_dir, results_dir, tables_dir\n","\n","\n","def initialize_data_loader():\n","    \"\"\"Initialize the data loading utility with required flags.\"\"\"\n","    return LoadData(INCLUDE_LAGS, INCLUDE_SEASON_VARS, INCLUDE_WEATHER, TUNER)\n","\n","def initialize_evaluation_metric():\n","    \"\"\"Initialize the evaluation metric utility with required flags.\"\"\"\n","    return EvaluationMetric(INCLUDE_LAGS, INCLUDE_SEASON_VARS, INCLUDE_WEATHER, TUNER)\n","\n","# ===== MAIN SCRIPT =====\n","\n","if __name__ == \"__main__\":\n","    # Setup directories based on TEST mode\n","    # dirs = setup_directories(TEST)\n","    IMAGE_PATH, LOG_DIR, TUNING_DIR, RESULTS_DIR, TABLES_DIR = setup_directories(\n","    test_mode=TEST, \n","    image_path=IMAGE_PATH, \n","    log_dir=LOG_DIR, \n","    tuning_dir=TUNING_DIR, \n","    results_dir=RESULTS_DIR, \n","    tables_dir=TABLES_DIR\n","    )\n","\n","    extra_info = get_extra_info()\n","    \n","    # Reload utils if changes were made\n","    reload_utils_misc()\n","\n","    # Initialize components\n","    load_data = initialize_data_loader()\n","    terminate_nan = TerminateNaN()\n","    evaluation_metric = initialize_evaluation_metric()\n","\n","    # Set random seeds for reproducibility\n","    tf.random.set_seed(14)\n","    np.random.seed(14)\n","\n","    # Log basic configuration\n","    logger.info(f\"Starting training with configuration:\")\n","    logger.info(f\"Data path: {DATA_PATH}\")\n","    logger.info(f\"Model path: {MODEL_PATH}\")\n","    logger.info(f\"Model path: {TUNING_DIR}\")\n","    logger.info(f\"Include Lags: {INCLUDE_LAGS}, Include Season Vars: {INCLUDE_SEASON_VARS}, Include Weather: {INCLUDE_WEATHER}\")\n","    logger.info(f\"Training epochs: {TRAINING_EPOCH}, Final model epochs: {FINAL_MODEL_EPOCH}, Batch size: {BATCH_SIZE}\")"]},{"cell_type":"markdown","id":"f013e083","metadata":{"id":"f013e083"},"source":["# All models"]},{"cell_type":"markdown","id":"99b2534c","metadata":{},"source":["## New setup"]},{"cell_type":"code","execution_count":null,"id":"c4b450c0","metadata":{},"outputs":[],"source":["#MODELS = ['LSTM','TCN', 'Hybrid', 'Transformer']\n","\n","for i in range(len(MODELS)):\n","    MODEL = MODELS[i]\n","    print(f'Model: {MODEL}')\n","    for i in range(len(TIME_END_PERIODS)):\n","        \n","        # Set the seed for reproducibility\n","        tf.random.set_seed(14)\n","        np.random.seed(14)\n","\n","        TIME_END = TIME_END_PERIODS[i]\n","        df, TIME_PERIOD = load_data.load_and_preprocess_data(DATA_PATH, TIME_START, TIME_END)\n","        print(f'Time period: {TIME_PERIOD}')\n","        log_dir, tuning_dir = load_data.setup_directories(LOG_DIR, TUNING_DIR, TIME_PERIOD, MODEL)\n","        datasets, y, X_train, X_test, scaler_y, y_test = load_data.split_and_scale_data(df)\n","        \n","        sequences_dict, scalers, X_test_scaled = load_data.prepare_sequences(df)\n","        datasets, y, X_train, X_test, scaler_y, y_test = load_data.split_and_scale_data(df)\n","        \n","        # Initialize and train the model\n","        trainer = ModelTrainer(datasets, log_dir, tuning_dir, LOSS, model_type=MODEL, sequences_dict=sequences_dict)\n","        final_model, history, best_hps, duration = trainer.train_model(BATCH_SIZE, TRAINING_EPOCH, FINAL_MODEL_EPOCH, overwrite=False)\n","        \n","        # Predictions and evaluation\n","        predictions = evaluation_metric.predict_full_sequence(final_model, X_test_scaled, scaler_y)\n","        if len(predictions) > len(y_test):\n","            predictions = predictions[:len(y_test)]\n","        else:\n","            y_test = y_test[:len(predictions)]\n","            \n","        evaluation_metric.evaluate_and_log(y_test, predictions, TIME_PERIOD, RESULTS_DIR, best_hps, duration, MODEL)\n","        \n","        # Plotting results\n","        plotting = Plotting(MODEL, TIME_PERIOD, IMAGE_PATH, INCLUDE_LAGS, INCLUDE_SEASON_VARS, INCLUDE_WEATHER, TUNER)\n","\n","        plotting.plot_predictions(df, y, X_train, X_test, np.array(predictions[:len(y_test)]))\n","        plotting.plot_training_history(history)\n","        plot_model(final_model, to_file=f'{IMAGE_PATH}/{MODEL}/{MODEL}_model{extra_info}_{TIME_PERIOD}.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"markdown","id":"9a53d868","metadata":{},"source":["## Single model"]},{"cell_type":"code","execution_count":null,"id":"0bc7738b","metadata":{},"outputs":[],"source":["MODEL = 'Transformer'\n","print(f'Model: {MODEL}')\n","\n","for i in range(len(TIME_END_PERIODS)):\n","    # Set the seed for reproducibility\n","    tf.random.set_seed(14)\n","    np.random.seed(14)\n","\n","    TIME_END = TIME_END_PERIODS[i]\n","    df, TIME_PERIOD = load_data.load_and_preprocess_data(DATA_PATH, TIME_START, TIME_END)\n","    print(f'Time period: {TIME_PERIOD}')\n","    log_dir, tuning_dir = load_data.setup_directories(LOG_DIR, TUNING_DIR, TIME_PERIOD, MODEL)\n","    sequences_dict, scalers, X_test_scaled = load_data.prepare_sequences(df)\n","    datasets, y, X_train, X_test, scaler_y, y_test = load_data.split_and_scale_data(df)\n","    \n","    # Initialize and train the model\n","    trainer = ModelTrainer(datasets, log_dir, tuning_dir, LOSS, model_type=MODEL, sequences_dict=sequences_dict)\n","    final_model, history, best_hps, duration = trainer.train_model(BATCH_SIZE, training_epoch=TRAINING_EPOCH, \n","                                                                   final_model_epoch=FINAL_MODEL_EPOCH, overwrite=False)\n","    \n","    # Predictions and evaluation\n","    predictions = evaluation_metric.predict_full_sequence(final_model, X_test_scaled, scaler_y)\n","    if len(predictions) > len(y_test):\n","        predictions = predictions[:len(y_test)]\n","    else:\n","        y_test = y_test[:len(predictions)]\n","        \n","    evaluation_metric.evaluate_and_log(y_test, predictions, TIME_PERIOD, RESULTS_DIR, best_hps, duration, MODEL)\n","    \n","    # Plotting results\n","    plotting = Plotting(MODEL, TIME_PERIOD, IMAGE_PATH, INCLUDE_LAGS, INCLUDE_SEASON_VARS, INCLUDE_WEATHER, TUNER)\n","\n","    plotting.plot_predictions(df, y, X_train, X_test, np.array(predictions[:len(y_test)]))\n","    plotting.plot_training_history(history)\n","    plot_model(final_model, to_file=f'{IMAGE_PATH}{MODEL}/{MODEL}_model{extra_info}_{TIME_PERIOD}.png', show_shapes=True, show_layer_names=True)"]},{"cell_type":"markdown","id":"c782e1ea","metadata":{},"source":["## SHAP Value"]},{"cell_type":"code","execution_count":null,"id":"5a8353bc","metadata":{},"outputs":[],"source":["MODEL = MODELS[1]\n","TIME_END = TIME_END_PERIODS[1]\n","df, TIME_PERIOD = load_data.load_and_preprocess_data(DATA_PATH, TIME_START, TIME_END)\n","print(f'Time period: {TIME_PERIOD}')\n","log_dir, tuning_dir = load_data.setup_directories(LOG_DIR, TUNING_DIR, TIME_PERIOD, MODEL)\n","datasets, y, X_train, X_test, scaler_y, y_test = load_data.split_and_scale_data(df)\n","\n","\n","print(len(X_test.columns))"]},{"cell_type":"code","execution_count":null,"id":"8d2afde5","metadata":{},"outputs":[],"source":["import shap\n","\n","for i in range(len(MODELS)):\n","    MODEL = MODELS[i]\n","    print(f'Model: {MODEL}')\n","    for i in range(len(TIME_END_PERIODS)):\n","        # Set the seed for reproducibility\n","        tf.random.set_seed(14)\n","        np.random.seed(14)\n","\n","        TIME_END = TIME_END_PERIODS[i]\n","        df, TIME_PERIOD = load_data.load_and_preprocess_data(DATA_PATH, TIME_START, TIME_END)\n","        print(f'Time period: {TIME_PERIOD}')\n","        log_dir, tuning_dir = load_data.setup_directories(LOG_DIR, TUNING_DIR, TIME_PERIOD, MODEL)\n","        datasets, y, X_train, X_test, scaler_y, y_test = load_data.split_and_scale_data(df)\n","        \n","        # Initialize and train the model\n","        trainer = ModelTrainer(datasets, log_dir, tuning_dir, LOSS, model_type=MODEL)\n","        final_model, history, best_hps, duration = trainer.train_model(BATCH_SIZE, TRAINING_EPOCH, FINAL_MODEL_EPOCH, overwrite=False)\n","\n","        # SHAP values\n","        sample_size = 100\n","        X_sample = np.squeeze(datasets['X_train'][:sample_size])  \n","        X_test_sample = np.squeeze(datasets['X_test'][:sample_size]) \n","        feature_names=X_test.columns\n","\n","        explainer = shap.Explainer(final_model, X_sample)\n","        shap_values = explainer(X_test_sample)\n","\n","        # Manually create an Explanation object to include feature names\n","        shap_values_with_names = shap.Explanation(\n","            values=shap_values,       # SHAP values from the model\n","            feature_names=feature_names, # Pass feature names\n","            data=X_test_sample          # Original data for SHAP\n","        )\n","        \n","        #Visualize SHAP values for LSTM\n","        shap.initjs()\n","\n","        # Create figure and axis\n","        fig, ax = plt.subplots()\n","\n","        shap.plots.bar(shap_values_with_names,show=False, ax=ax, max_display=len(shap_values_with_names))\n","        plt.savefig(f'{IMAGE_PATH}{MODEL}/{MODEL}_shap_bar_{TIME_PERIOD}_{extra_info}_sample_{sample_size}.png', bbox_inches='tight')  # Save as PNG (you can choose other formats like PDF)\n","        plt.close()\n","        shap.plots.beeswarm(shap_values_with_names, max_display=len(shap_values_with_names), show=False)\n","        plt.savefig(f'{IMAGE_PATH}{MODEL}/{MODEL}_shap_beeswarm_{TIME_PERIOD}_{extra_info}_sample_{sample_size}.png', bbox_inches='tight')  # Save as PNG (you can choose other formats like PDF)\n","        plt.close()\n","        shap.plots.waterfall(shap_values_with_names[0],show=False)\n","        plt.savefig(f'{IMAGE_PATH}{MODEL}/{MODEL}_shap_waterfall_{TIME_PERIOD}_{extra_info}_sample_{sample_size}.png', bbox_inches='tight')  # Save as PNG (you can choose other formats like PDF)\n","        plt.close()\n","\n","        # Force plot (for the first instance)\n","        force_plot = shap.plots.force(shap_values_with_names[0])\n","\n","        # Save force plot as HTML\n","        shap.save_html(f'{IMAGE_PATH}{MODEL}/{MODEL}_shap_force_plot_{TIME_PERIOD}_{extra_info}_sample_{sample_size}.html', force_plot)"]},{"cell_type":"code","execution_count":null,"id":"7a8698e5","metadata":{},"outputs":[],"source":["import shap\n","from tqdm import tqdm\n","\n","# Wrap the outer loop with tqdm for model progress\n","for i in tqdm(range(len(MODELS)), desc=\"Processing Models\"):\n","    MODEL = MODELS[i]\n","    print(f'Model: {MODEL}')\n","    \n","    # Wrap the inner loop with tqdm for time period progress\n","    for i in tqdm(range(len(TIME_END_PERIODS)), desc=\"Processing Time Periods\", leave=False):\n","        # Set the seed for reproducibility\n","        tf.random.set_seed(14)\n","        np.random.seed(14)\n","\n","        TIME_END = TIME_END_PERIODS[i]\n","        df, TIME_PERIOD = load_data.load_and_preprocess_data(DATA_PATH, TIME_START, TIME_END)\n","        print(f'Time period: {TIME_PERIOD}')\n","        log_dir, tuning_dir = load_data.setup_directories(LOG_DIR, TUNING_DIR, TIME_PERIOD, MODEL)\n","        datasets, y, X_train, X_test, scaler_y, y_test = load_data.split_and_scale_data(df)\n","        \n","        # Initialize and train the model\n","        trainer = ModelTrainer(datasets, log_dir, tuning_dir, LOSS, model_type=MODEL)\n","        final_model, history, best_hps, duration = trainer.train_model(BATCH_SIZE, TRAINING_EPOCH, FINAL_MODEL_EPOCH, overwrite=False)\n","\n","        # SHAP values\n","        sample_size = 100\n","        X_sample = np.squeeze(datasets['X_train'][:sample_size])\n","        X_test_sample = np.squeeze(datasets['X_test'][:sample_size])\n","        feature_names = X_test.columns\n","\n","        explainer = shap.Explainer(final_model, X_sample)\n","        shap_values = explainer(X_test_sample)\n","\n","        # Manually create an Explanation object to include feature names\n","        shap_values_with_names = shap.Explanation(\n","            values=shap_values,       # SHAP values from the model\n","            feature_names=feature_names, # Pass feature names\n","            data=X_test_sample          # Original data for SHAP\n","        )\n","        \n","        # Visualize SHAP values for LSTM\n","        shap.initjs()\n","\n","        # Create figure and axis\n","        fig, ax = plt.subplots()\n","        shap.plots.bar(shap_values_with_names, show=False, ax=ax, max_display=len(shap_values_with_names))\n","        plt.savefig(f'{IMAGE_PATH}{MODEL}/{MODEL}_shap_bar_{TIME_PERIOD}_{extra_info}_sample_{sample_size}.png', bbox_inches='tight')\n","        plt.close()\n","        \n","        shap.plots.beeswarm(shap_values_with_names, max_display=len(shap_values_with_names), show=False)\n","        plt.savefig(f'{IMAGE_PATH}{MODEL}/{MODEL}_shap_beeswarm_{TIME_PERIOD}_{extra_info}_sample_{sample_size}.png', bbox_inches='tight')\n","        plt.close()\n","        \n","        shap.plots.waterfall(shap_values_with_names[0], show=False)\n","        plt.savefig(f'{IMAGE_PATH}{MODEL}/{MODEL}_shap_waterfall_{TIME_PERIOD}_{extra_info}_sample_{sample_size}.png', bbox_inches='tight')\n","        plt.close()\n","\n","        # Force plot (for the first instance)\n","        force_plot = shap.plots.force(shap_values_with_names[0])\n","\n","        # Save force plot as HTML\n","        shap.save_html(f'{IMAGE_PATH}{MODEL}/{MODEL}_shap_force_plot_{TIME_PERIOD}_{extra_info}_sample_{sample_size}.html', force_plot)\n"]},{"cell_type":"code","execution_count":null,"id":"8558e779","metadata":{},"outputs":[],"source":["#Visualize SHAP values for LSTM\n","shap.initjs()\n","\n","# Create figure and axis\n","fig, ax = plt.subplots()\n","\n","shap.plots.bar(shap_values_with_names, ax=ax, max_display=len(shap_values_with_names))\n","shap.plots.beeswarm(shap_values_with_names, max_display=len(shap_values_with_names))\n","shap.plots.waterfall(shap_values_with_names[0], max_display=len(shap_values_with_names))\n","shap.plots.force(shap_values_with_names[0])"]},{"cell_type":"markdown","id":"f8292af4","metadata":{},"source":["# Diebold-Mariano"]},{"cell_type":"code","execution_count":null,"id":"6bdc5fcf","metadata":{},"outputs":[],"source":["import pickle\n","\n","\n","TIME_END = TIME_END_PERIODS[2]\n","print(f'Time end: {TIME_END}')\n","MODEL = 'Hybrid'\n","df, TIME_PERIOD = load_data.load_and_preprocess_data(DATA_PATH, TIME_START, TIME_END)\n","print(f'Time period: {TIME_PERIOD}')\n","\n","log_dir, tuning_dir = load_data.setup_directories(LOG_DIR, TUNING_DIR, TIME_PERIOD, MODEL)\n","datasets, y, X_train, X_test, scaler_y, y_test = load_data.split_and_scale_data(df)"]},{"cell_type":"code","execution_count":null,"id":"6a3195a0","metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from statsmodels.tsa.stattools import acf\n","from scipy import stats\n","\n","#mae = metrics.mae(np.array(y_test[:len(predictions)]), np.array(predictions))\n","\n","errors_model1 = np.abs(np.array(y_test[:len(predictions)]) - predictions_1)\n","errors_model2 = np.abs(np.array(y_test[:len(predictions)]) - predictions_2)\n","d = errors_model1 - errors_model2\n","print(d)\n","\n","# Sample function for Diebold-Mariano test\n","def diebold_mariano_test(errors_model1, errors_model2):\n","    d = errors_model1 - errors_model2\n","    d = np.ravel(d)\n","    mean_d = np.mean(d)\n","    acf_values = acf(d, fft=True)\n","    variance_d = np.var(d) * (1 + 2 * sum(acf_values[1:])) / len(d)\n","    dm_stat = mean_d / np.sqrt(variance_d)\n","    p_value = 2 * (1 - stats.norm.cdf(abs(dm_stat)))\n","    return dm_stat, p_value\n","\n","# Perform Diebold-Mariano test on the errors\n","dm_stat, p_value = diebold_mariano_test(errors_model1, errors_model2)\n","print(f\"Diebold-Mariano Test Statistic: {dm_stat}\")\n","print(f\"P-Value: {p_value}\")\n","\n","# Interpretation\n","if p_value < 0.05:\n","    print(\"The difference in forecasting errors is statistically significant.\")\n","else:\n","    print(\"The difference in forecasting errors is not statistically significant.\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":5}
