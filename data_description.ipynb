{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to describe the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from utils import misc\n",
    "import sys\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "\n",
    "\n",
    "root_path = ''\n",
    "data_path = f'{root_path}data/final_dataset_test.csv'\n",
    "model_path = f'{root_path}models/'\n",
    "path_to_images = f'{root_path}images/'\n",
    "base_log_dir = f'{model_path}logs/'\n",
    "base_tuning_dir = f'{model_path}tuning/'\n",
    "results_dir = f'{root_path}results/'\n",
    "tables_dir = f'{root_path}tables/'\n",
    "\n",
    "# Specify the desired start and end time\n",
    "start_time = pd.Timestamp(2019, 10, 31)\n",
    "end_time = pd.Timestamp(2024, 7, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.misc import LoadData\n",
    "\n",
    "load_data = LoadData()\n",
    "df, TIME_PERIOD = load_data.load_and_preprocess_data(data_path, start_time, end_time)\n",
    "#df, time_period = misc.LoadData.load_and_preprocess_data(data_path, start_time, end_time) # Load and preprocess data\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TIME_START = '2019-10-31'\n",
    "TIME_END_PERIODS = ['2021-09-30', '2023-01-01', '2024-07-01']\n",
    "load_data = LoadData()\n",
    "\n",
    "def calculate_metrics(column):\n",
    "    metrics = {\n",
    "        '# of Observations': len(column),\n",
    "        'Min': column.min(),\n",
    "        'Max': column.max(),\n",
    "        'Mean': column.mean(),\n",
    "        'Standard deviation': column.std(),\n",
    "        'Skewness': skew(column),\n",
    "        'Kurtosis': kurtosis(column)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "for i in range(len(TIME_END_PERIODS)):\n",
    "    TIME_END = TIME_END_PERIODS[i]\n",
    "    df, TIME_PERIOD = load_data.load_and_preprocess_data(data_path, TIME_START, TIME_END)\n",
    "    # Function to calculate descriptive statistics for a given column\n",
    "\n",
    "\n",
    "    # Apply the function to each column in the DataFrame\n",
    "    # Apply the function to the 'Day Ahead Spot Price' column\n",
    "    results = calculate_metrics(df['Day Ahead Spot Price'])\n",
    "\n",
    "    # Convert results to a DataFrame by wrapping in a list\n",
    "    results_df = pd.DataFrame([results])  # Wrapping in a list converts dictionary to one-row DataFrame\n",
    "    #results_df = results_df.T  # Transpose for readability\n",
    "    #results_df.columns = ['Day Ahead Spot Price']  # Add column name for clarity\n",
    "\n",
    "    print(results_df)\n",
    "    latex_table = results_df.to_latex(buf=f'{tables_dir}day-ahead_prices_from_{TIME_START}_to_{TIME_END}.tex',\n",
    "                                      index=True, \n",
    "                                  caption=f'Descriptive statistics of day-ahead prices from {TIME_START} to {TIME_END}.',\n",
    "                                  label=\"table:descriptive_stats\",\n",
    "                                  column_format=\"lccccccc\",\n",
    "                                  header=True, \n",
    "                                  bold_rows=True)\n",
    "    \n",
    "    # Generate and save a histogram for the 'Day Ahead Spot Price' column\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    #plt.hist(df['Day Ahead Spot Price'], bins=50, color='skyblue', edgecolor='black')\n",
    "    sns.histplot(df['Day Ahead Spot Price'], bins=100, kde=True, color='skyblue', edgecolor='black')\n",
    "    plt.title(f\"Histogram of Day-Ahead Prices from {TIME_START} to {TIME_END}\")\n",
    "    plt.xlabel(\"Day-Ahead Price\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{path_to_images}day_ahead_price_histogram_{TIME_START}_to_{TIME_END}.png')\n",
    "    plt.close()                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Initialize variables and load_data object\n",
    "TIME_START = '2019-10-31'\n",
    "TIME_END_PERIODS = ['2021-09-30', '2023-01-01', '2024-07-01']\n",
    "load_data = LoadData()\n",
    "\n",
    "# Function to calculate descriptive statistics for a given column\n",
    "def calculate_metrics(column):\n",
    "    metrics = {\n",
    "        '# of Observations': len(column),\n",
    "        'Min': column.min(),\n",
    "        'Max': column.max(),\n",
    "        'Mean': column.mean(),\n",
    "        'Standard deviation': column.std(),\n",
    "        'Skewness': skew(column),\n",
    "        'Kurtosis': kurtosis(column)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "# List to store results for each time period\n",
    "all_results = []\n",
    "\n",
    "for i, TIME_END in enumerate(TIME_END_PERIODS):\n",
    "    df, TIME_PERIOD = load_data.load_and_preprocess_data(data_path, TIME_START, TIME_END)\n",
    "    \n",
    "    # Calculate metrics for 'Day Ahead Spot Price' column\n",
    "    results = calculate_metrics(df['Day Ahead Spot Price'])\n",
    "    \n",
    "    # Convert results to a DataFrame and add a column for the time period\n",
    "    results_df = pd.DataFrame([results])\n",
    "    results_df.insert(0, 'Time Period', TIME_PERIOD)  # Insert time period as the first column\n",
    "    print(results_df)\n",
    "    # Append results to the list\n",
    "    all_results.append(results_df)\n",
    "\n",
    "# Concatenate all results into a single DataFrame\n",
    "combined_results_df = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Round all numerical columns to two decimal places\n",
    "combined_results_df = combined_results_df.round(2)\n",
    "\n",
    "# Round each column to two decimal places and convert to string format\n",
    "for col in combined_results_df.columns[1:]:  # Skip 'Time Period' column\n",
    "    combined_results_df[col] = combined_results_df[col].apply(lambda x: f\"{x:.2f}\")\n",
    "\n",
    "\n",
    "# Export combined results to LaTeX\n",
    "latex_table = combined_results_df.to_latex(\n",
    "    index=False,\n",
    "    caption=\"Descriptive statistics of day-ahead prices across different time periods.\",\n",
    "    label=\"table:combined_descriptive_stats\",\n",
    "    column_format=\"lccccccc\",\n",
    "    header=True,\n",
    "    bold_rows=True\n",
    ")\n",
    "\n",
    "# Save LaTeX output\n",
    "with open(f'{tables_dir}day_ahead_descriptive_across_datasets.tex', 'w') as f:\n",
    "    f.write(latex_table)\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "correlation_matrix = df.corr()  # Calculate correlation matrix\n",
    "\n",
    "# Set the size of the figure\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "# Draw the heatmap with annotation and the coolwarm colormap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='viridis', vmin=-1, vmax=1)\n",
    "\n",
    "# Display the plot\n",
    "plt.savefig(f'{path_to_images}correlation/correlation_matrix_{time_period}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "# Sample data creation: replace this with your actual Series\n",
    "# Assume `prices` is your Series with a datetime index\n",
    "prices = df['Day Ahead Spot Price']\n",
    "\n",
    "# Resampling the Series into specific time frames\n",
    "daily_1 = prices.resample('D').mean()  # 1 day\n",
    "daily_2 = prices.resample('2D').mean()  # 2 days\n",
    "weekly_1 = prices.resample('W').mean()  # 1 week\n",
    "weekly_2 = prices.resample('2W').mean()  # 2 weeks\n",
    "monthly_1 = prices.resample('ME').mean()  # 1 month\n",
    "monthly_2 = prices.resample('2ME').mean()  # 2 months\n",
    "monthly_3 = prices.resample('3ME').mean()  # 3 months\n",
    "quarterly_1 = prices.resample('QE').mean()  # 1 quarter\n",
    "quarterly_2 = prices.resample('2QE').mean()  # 2 quarters\n",
    "quarterly_3 = prices.resample('3QE').mean()  # 3 quarters\n",
    "quarterly_4 = prices.resample('4QE').mean()  # 4 quarters\n",
    "yearly_1 = prices.resample('YE').mean()  # 1 year\n",
    "yearly_2 = prices.resample('2YE').mean()  # 2 years\n",
    "yearly_3 = prices.resample('3YE').mean()  # 3 years\n",
    "yearly_4 = prices.resample('4YE').mean()  # 4 years\n",
    "\n",
    "# Combine all resampled series into a DataFrame\n",
    "data = pd.DataFrame({\n",
    "    '1D': daily_1,\n",
    "    '2D': daily_2,\n",
    "    '1W': weekly_1,\n",
    "    '2W': weekly_2,\n",
    "    '1M': monthly_1,\n",
    "    '2M': monthly_2,\n",
    "    '3M': monthly_3,\n",
    "    '1Q': quarterly_1,\n",
    "    '2Q': quarterly_2,\n",
    "    '3Q': quarterly_3,\n",
    "    '4Q': quarterly_4,\n",
    "    '1Y': yearly_1,\n",
    "    '2Y': yearly_2,\n",
    "    '3Y': yearly_3,\n",
    "    '4Y': yearly_4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation_matrix = data.corr()\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='viridis', vmin=-1, vmax=1)\n",
    "\n",
    "# Add a title\n",
    "plt.title('Correlation Matrix of Electricity Prices Across Different Time Periods')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "plt.savefig(f'{path_to_images}correlation/correlation_matrix_across_time_{time_period}.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(df.head())\n",
    "# Calculate mean and confidence intervals\n",
    "data = df\n",
    "mean_price = data['Day Ahead Spot Price'].mean()\n",
    "confidence_interval = 1.96 * data['Day Ahead Spot Price'].std() / np.sqrt(len(data))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(data.index, data['Day Ahead Spot Price'], label='Electricity Price', color='blue')\n",
    "plt.fill_between(data.index, mean_price - confidence_interval, mean_price + confidence_interval, color='orange', alpha=0.3, label=\"95% Confidence Interval\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Electricity Price\")\n",
    "plt.legend()\n",
    "plt.title(\"Electricity Prices with Confidence Interval\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is already defined and contains 'Day Ahead Spot Price'\n",
    "\n",
    "# Get the hourly data and calculate statistics\n",
    "data = df['Day Ahead Spot Price']\n",
    "hours = pd.date_range('00:00:00', '23:00:00', freq='1h').hour\n",
    "\n",
    "mean = data.groupby(data.index.hour).mean()\n",
    "median = data.groupby(data.index.hour).median()\n",
    "std = data.groupby(data.index.hour).std()\n",
    "min = data.groupby(data.index.hour).min()\n",
    "max = data.groupby(data.index.hour).max()\n",
    "skew = data.groupby(data.index.hour).skew()\n",
    "kur = data.groupby(data.index.hour).apply(lambda x: x.kurtosis())\n",
    "\n",
    "lower = data.quantile(0.05)\n",
    "upper = data.quantile(0.95)\n",
    "meanclipped = data.clip(lower=lower, upper=upper).groupby(data.index.hour).mean()\n",
    "skewclipped = data.clip(lower=lower, upper=upper).groupby(data.index.hour).skew()\n",
    "kurclipped = data.clip(lower=lower, upper=upper).groupby(data.index.hour).apply(lambda x: x.kurtosis())\n",
    "\n",
    "# Create DataFrame with hours as integers\n",
    "mean_df = pd.DataFrame({\n",
    "    'Hour': hours, \n",
    "    'Mean': mean, \n",
    "    'Mean w/o outliers': meanclipped, \n",
    "    'Median': median, \n",
    "    'Std': std,\n",
    "    'Skew': skew, \n",
    "    'Skew w/o outliers': skewclipped,\n",
    "    'Kurtosis': kur,\n",
    "    'Kurtosis w/o outliers': kurclipped\n",
    "}).reset_index(drop=True).round(2)\n",
    "\n",
    "# Export to LaTeX with columns centered except the first one\n",
    "mean_df.to_latex(buf=f'{tables_dir}day_ahead_descriptive.tex', index=False, \n",
    "                 caption=\"Descriptive statistics of Day Ahead Spot Prices for every hour of day\", \n",
    "                 label='DayAheadDescriptive', float_format='%.2f', \n",
    "                 column_format='l' + 'c' * (len(mean_df.columns) - 1))\n",
    "\n",
    "mean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = {}\n",
    "for i in range(24):\n",
    "    hours[i] = data.loc[df.index.hour==i]\n",
    "\n",
    "mean = []\n",
    "meanclip = []\n",
    "skew = []\n",
    "skewclip = []\n",
    "minimum = []\n",
    "outlier_low = []\n",
    "outlier_high = []\n",
    "maximum = []\n",
    "spikes_low = []\n",
    "spikes_high = []\n",
    "    \n",
    "for i in [*hours]:\n",
    "    iqr = hours[i].quantile(.75)-hours[i].quantile(.25)\n",
    "    outlier_l = hours[i].quantile(.25)-3*iqr\n",
    "    outlier_h = hours[i].quantile(.75)+3*iqr\n",
    "    \n",
    "    mean.append(hours[i].mean())\n",
    "    skew.append(hours[i].skew())\n",
    "    minimum.append(hours[i].min())\n",
    "    outlier_low.append(outlier_l)\n",
    "    outlier_high.append(outlier_h)\n",
    "    maximum.append(hours[i].max())\n",
    "    \n",
    "    no_spikes_low = (hours[i]<outlier_l).sum()\n",
    "    no_spikes_high = (hours[i]>outlier_h).sum()\n",
    "    sh_spikes_low =  no_spikes_low/len(hours[i])\n",
    "    sh_spikes_high =  no_spikes_high/len(hours[i])\n",
    "    spikes_low.append(sh_spikes_low*100)\n",
    "    spikes_high.append(sh_spikes_high*100)\n",
    "    \n",
    "    clip = hours[i].loc[(hours[i]>outlier_l) & (hours[i]<outlier_h)]\n",
    "\n",
    "    meanclip.append(clip.mean())\n",
    "    skewclip.append(clip.skew())\n",
    "    \n",
    "desc = {'Mean': mean, 'Mean w/o outliers': meanclip, 'Skew': skew, 'Skew w/o outliers': skewclip, 'Min': minimum, 'Max': maximum, 'Spikes (%)': np.array(spikes_low)+np.array(spikes_high)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame structure; replace with your actual DataFrame containing hourly prices.\n",
    "# Let's assume your DataFrame is called 'data' and has a DateTimeIndex and a 'price' column.\n",
    "\n",
    "# Filter the data to match the provided start and end time\n",
    "start_time = pd.Timestamp(2019, 10, 31)\n",
    "end_time = pd.Timestamp(2024, 7, 2)\n",
    "filtered_data = data[(data.index >= start_time) & (data.index <= end_time)]\n",
    "\n",
    "# Create a list to hold rows for each year\n",
    "rows = []\n",
    "\n",
    "# Resample by monthly and quarterly frequencies and calculate the mean of each period\n",
    "for year in range(start_time.year, end_time.year + 1):\n",
    "    # Filter for the current year\n",
    "    year_data = filtered_data[filtered_data.index.year == year]\n",
    "    \n",
    "    # Monthly averages (1M, 2M, 3M)\n",
    "    monthly_avg = year_data.resample('M').mean()\n",
    "    \n",
    "    # Quarterly averages (1Q, 2Q, 3Q, 4Q)\n",
    "    quarterly_avg = year_data.resample('Q').mean()\n",
    "\n",
    "    # Combine the monthly and quarterly averages\n",
    "    row = {\n",
    "        '1M': monthly_avg.iloc[0] if len(monthly_avg) > 0 else None,\n",
    "        '2M': monthly_avg.iloc[1] if len(monthly_avg) > 1 else None,\n",
    "        '3M': monthly_avg.iloc[2] if len(monthly_avg) > 2 else None,\n",
    "        '1Q': quarterly_avg.iloc[0] if len(quarterly_avg) > 0 else None,\n",
    "        '2Q': quarterly_avg.iloc[1] if len(quarterly_avg) > 1 else None,\n",
    "        '3Q': quarterly_avg.iloc[2] if len(quarterly_avg) > 2 else None,\n",
    "        '4Q': quarterly_avg.iloc[3] if len(quarterly_avg) > 3 else None\n",
    "    }\n",
    "    \n",
    "    # Append the row dictionary to the list\n",
    "    rows.append(pd.DataFrame(row, index=[year]))\n",
    "\n",
    "# Concatenate all rows into a final DataFrame\n",
    "result_table = pd.concat(rows)\n",
    "\n",
    "# Set the index as 'SYS'\n",
    "result_table.index.name = 'DK1'\n",
    "\n",
    "# Display the result\n",
    "print(result_table)\n",
    "\n",
    "# You can save it to a file if needed\n",
    "# result_table.to_csv('electricity_price_summary.csv')\n",
    "result_table.round(2).to_latex(buf=f'{tables_dir}average_traded_prices.tex', \n",
    "                               index=True,\n",
    "                                 caption=\"Average traded prices across different time periods\", \n",
    "                                 label='average_traded_prices',\n",
    "                                 float_format='%.2f',\n",
    "                                 column_format='l' + 'c' * (len(result_table.columns) - 1))\n",
    "                 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Electricity balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "start_date = start_time.strftime('%Y-%m-%d') #2015-01-01'\n",
    "end_date = end_time.strftime('%Y-%m-%d') #'2022-06-01'\n",
    "\n",
    "price_area  = '{\"PriceArea\":[\"DK1\"]}'\n",
    "url = f'https://api.energidataservice.dk/dataset/ElectricityBalanceNonv?offset=0&start={start_date}&end={end_date}&filter=%7B%22PriceArea%22:[%22DK1%22]%7D&sort=HourUTC%20DESC'\n",
    "response = requests.get(\n",
    "    url=url)\n",
    "\n",
    "if response.ok:  # More idiomatic way to check for a successful request\n",
    "    records = response.json().get('records', [])\n",
    "    # Directly filtering necessary columns and renaming them\n",
    "    el_balance = (pd.json_normalize(records).drop(columns=['HourDK', 'PriceArea'])\n",
    "                          #.loc[:, ['HourUTC', 'SpotPriceDKK']]\n",
    "                          #.rename(columns={'HourUTC': 'time', 'SpotPriceDKK': 'SpotPriceDK1'})\n",
    "                          )\n",
    "\n",
    "    # Convert 'time' column to datetime without timezone information\n",
    "    #data_el_spot_DK1['time'] = pd.to_datetime(data_el_spot_DK1['time']).dt.tz_localize(None)\n",
    "\n",
    "    # Display the first few rows of the processed DataFrame\n",
    "    print(el_balance.head())\n",
    "else:\n",
    "    print(f\"Failed to fetch data: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame\n",
    "#el_balance = pd.DataFrame(data)\n",
    "\n",
    "# Calculate shares of each energy source with respect to TotalLoad\n",
    "sources = [\n",
    "    'Biomass', 'FossilGas', 'FossilHardCoal', \n",
    "    'FossilOil', 'HydroPower', 'OtherRenewable', \n",
    "    'SolarPower', 'Waste', 'OnshoreWindPower', \n",
    "    'OffshoreWindPower'\n",
    "]\n",
    "\n",
    "for source in sources:\n",
    "    el_balance[f'{source}_share'] = (el_balance[source] / el_balance['TotalLoad']) * 100\n",
    "\n",
    "# Display the modified DataFrame with shares\n",
    "print(el_balance.head())\n",
    "el_balance.to_csv(f'{root_path}data/electricity_balance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the HourUTC column as the index for plotting\n",
    "el_balance['HourUTC'] = pd.to_datetime(el_balance['HourUTC'])\n",
    "el_balance.set_index('HourUTC', inplace=True)\n",
    "\n",
    "# Plotting the shares\n",
    "plt.figure(figsize=(12, 6))\n",
    "for source in sources:\n",
    "    plt.plot(el_balance.index, el_balance[f'{source}_share'], marker='', label=source)\n",
    "\n",
    "plt.title('Shares of Energy Sources with Respect to Total Load')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Share (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Energy Sources')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate monthly averages\n",
    "monthly_averages = el_balance.resample('ME').mean()\n",
    "\n",
    "label_mapping = {\n",
    "    'Biomass': 'Biomass',\n",
    "    'FossilGas': 'Fossil Gas',\n",
    "    'FossilHardCoal': 'Fossil Hard Coal',\n",
    "    'FossilOil': 'Fossil Oil',\n",
    "    'HydroPower': 'Hydro Power',\n",
    "    'OtherRenewable': 'Other Renewable',\n",
    "    'SolarPower': 'Solar Power',\n",
    "    'Waste': 'Waste',\n",
    "    'OnshoreWindPower': 'Onshore Wind Power',\n",
    "    'OffshoreWindPower': 'Offshore Wind Power'\n",
    "}\n",
    "\n",
    "# Optional: You can plot the monthly averages if needed\n",
    "plt.figure(figsize=(12, 6))\n",
    "for source in sources:\n",
    "    plt.plot(monthly_averages.index, monthly_averages[f'{source}_share'], marker='', label=label_mapping[source])\n",
    "\n",
    "plt.title('')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Average Share (%)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Energy Sources')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.savefig(f'{path_to_images}energy_sources_share.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
